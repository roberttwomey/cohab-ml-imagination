{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K74zxktiQyub"
   },
   "source": [
    "# **StyleGANXL + CLIP 🖼️**\n",
    "\n",
    "OOD Users try `torch-gpu-stylegan` image. \n",
    "\n",
    "## Generate images from text prompts using StyleGANXL with CLIP guidance.\n",
    "\n",
    "(Modified by Katherine Crowson to optimize in W+ space)\n",
    "\n",
    "This notebook is a work in progress, head over [here](https://github.com/CasualGANPapers/unconditional-StyleGAN-CLIP) if you want to be up to date with its changes.\n",
    "\n",
    "Largely based on code by  [Katherine Crowson](https://github.com/crowsonkb) and [nshepperd](https://github.com/nshepperd).\n",
    "\n",
    "Mostly made possible because of [StyleGAN-XL](https://github.com/autonomousvision/stylegan_xl) and [CLIP](https://github.com/openai/CLIP).\n",
    "\n",
    "Created by [Eugenio Herrera](https://github.com/ouhenio) and [Rodrigo Mello](https://github.com/ryudrigo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown #**Install libraries and define functions** 🏗️🛠️\n",
    "# @markdown This cell will take a little while because it has to download several libraries.\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "# !git clone https://github.com/autonomousvision/stylegan_xl\n",
    "# !git clone https://github.com/openai/CLIP\n",
    "# !pip install -e ./CLIP\n",
    "\n",
    "# !pip install einops ninja\n",
    "# !pip install timm\n",
    "%pip install dill\n",
    "%pip install timm\n",
    "%pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6Ri2kT3N3Gc",
    "outputId": "cb1dca3e-fcaa-4b73-f52c-72dc2f22820d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## I'll probably have to trim stuff here\n",
    "\n",
    "import sys\n",
    "# sys.path.append('./CLIP')\n",
    "sys.path.append('./stylegan_xl')\n",
    "\n",
    "import io\n",
    "import os, time, glob\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import clip\n",
    "import unicodedata\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from IPython.display import display\n",
    "from einops import rearrange\n",
    "# from google.colab import files\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print('Using device:', device, file=sys.stderr)\n",
    "\n",
    "# Functions (many must be trimmed too)\n",
    "\n",
    "def fetch(url_or_path):\n",
    "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
    "        r = requests.get(url_or_path)\n",
    "        r.raise_for_status()\n",
    "        fd = io.BytesIO()\n",
    "        fd.write(r.content)\n",
    "        fd.seek(0)\n",
    "        return fd\n",
    "    return open(url_or_path, 'rb')\n",
    "\n",
    "def fetch_model(url_or_path):\n",
    "    !wget -nc -c '{url_or_path}' -P /work/emar349/shared/stylegan-xl/\n",
    "\n",
    "def slugify(value, allow_unicode=False):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/django/django/blob/master/django/utils/text.py\n",
    "    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n",
    "    dashes to single dashes. Remove characters that aren't alphanumerics,\n",
    "    underscores, or hyphens. Convert to lowercase. Also strip leading and\n",
    "    trailing whitespace, dashes, and underscores.\n",
    "    \"\"\"\n",
    "    value = str(value)\n",
    "    if allow_unicode:\n",
    "        value = unicodedata.normalize('NFKC', value)\n",
    "    else:\n",
    "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
    "    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
    "    return re.sub(r'[-\\s]+', '-', value).strip('-_')\n",
    "\n",
    "def norm1(prompt):\n",
    "    \"Normalize to the unit sphere.\"\n",
    "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
    "\n",
    "def spherical_dist_loss(x, y):\n",
    "    x = F.normalize(x, dim=-1)\n",
    "    y = F.normalize(y, dim=-1)\n",
    "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
    "\n",
    "def prompts_dist_loss(x, targets, loss):\n",
    "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
    "      return loss(x, targets[0])\n",
    "    distances = [loss(x, target) for target in targets]\n",
    "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
    "\n",
    "class MakeCutouts(torch.nn.Module):\n",
    "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
    "        super().__init__()\n",
    "        self.cut_size = cut_size\n",
    "        self.cutn = cutn\n",
    "        self.cut_pow = cut_pow\n",
    "\n",
    "    def forward(self, input):\n",
    "        sideY, sideX = input.shape[2:4]\n",
    "        max_size = min(sideX, sideY)\n",
    "        min_size = min(sideX, sideY, self.cut_size)\n",
    "        cutouts = []\n",
    "        for _ in range(self.cutn):\n",
    "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
    "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
    "            offsety = torch.randint(0, sideY - size + 1, ())\n",
    "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
    "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
    "        return torch.cat(cutouts)\n",
    "\n",
    "make_cutouts = MakeCutouts(224, 32, 0.5)\n",
    "\n",
    "def embed_image(image):\n",
    "  n = image.shape[0]\n",
    "  cutouts = make_cutouts(image)\n",
    "  embeds = clip_model.embed_cutout(cutouts)\n",
    "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
    "  return embeds\n",
    "\n",
    "def embed_url(url):\n",
    "  image = Image.open(fetch(url)).convert('RGB')\n",
    "  return embed_image(TF.to_tensor(image).to(device).unsqueeze(0)).mean(0).squeeze(0)\n",
    "\n",
    "class CLIP(object):\n",
    "  def __init__(self):\n",
    "    clip_model = \"ViT-B/16\"\n",
    "    self.model, _ = clip.load(clip_model)\n",
    "    self.model = self.model.requires_grad_(False)\n",
    "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def embed_text(self, prompt):\n",
    "      \"Normalized clip text embedding.\"\n",
    "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
    "\n",
    "  def embed_cutout(self, image):\n",
    "      \"Normalized clip image embedding.\"\n",
    "      return norm1(self.model.encode_image(self.normalize(image)))\n",
    "  \n",
    "clip_model = CLIP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guZeRGM6OmaU",
    "outputId": "e88b2d38-70ef-4b20-ab1d-32a6285ddb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘/work/emar349/shared/stylegan-xl/imagenet512.pkl’ already there; not retrieving.\n",
      "\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Failed!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Ninja is required to load C++ extensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     26\u001b[0m   cs[i,i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 27\u001b[0m w_stds \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m w_stds \u001b[38;5;241m=\u001b[39m w_stds\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1000\u001b[39m, G\u001b[38;5;241m.\u001b[39mnum_ws, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m w_stds\u001b[38;5;241m=\u001b[39mw_stds\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m<string>:170\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, z, c, truncation_psi, truncation_cutoff, update_emas)\u001b[0m\n",
      "File \u001b[0;32m/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m<string>:105\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
      "File \u001b[0;32m~/ml-art-test/stylegan-xl/./stylegan_xl/torch_utils/ops/bias_act.py:84\u001b[0m, in \u001b[0;36mbias_act\u001b[0;34m(x, b, dim, act, alpha, gain, clamp, impl)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impl \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _bias_act_cuda(dim\u001b[38;5;241m=\u001b[39mdim, act\u001b[38;5;241m=\u001b[39mact, alpha\u001b[38;5;241m=\u001b[39malpha, gain\u001b[38;5;241m=\u001b[39mgain, clamp\u001b[38;5;241m=\u001b[39mclamp)\u001b[38;5;241m.\u001b[39mapply(x, b)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bias_act_ref(x\u001b[38;5;241m=\u001b[39mx, b\u001b[38;5;241m=\u001b[39mb, dim\u001b[38;5;241m=\u001b[39mdim, act\u001b[38;5;241m=\u001b[39mact, alpha\u001b[38;5;241m=\u001b[39malpha, gain\u001b[38;5;241m=\u001b[39mgain, clamp\u001b[38;5;241m=\u001b[39mclamp)\n",
      "File \u001b[0;32m~/ml-art-test/stylegan-xl/./stylegan_xl/torch_utils/ops/bias_act.py:41\u001b[0m, in \u001b[0;36m_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _plugin\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _plugin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     _plugin \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_plugin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act_plugin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act.cpp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act.cu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act.h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--use_fast_math\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/ml-art-test/stylegan-xl/./stylegan_xl/torch_utils/custom_ops.py:136\u001b[0m, in \u001b[0;36mget_plugin\u001b[0;34m(module_name, sources, headers, source_dir, **build_kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Compile.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     cached_sources \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cached_build_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(fname)) \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m sources]\n\u001b[0;32m--> 136\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpp_extension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_build_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_build\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_sources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuild_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcpp_extension\u001b[38;5;241m.\u001b[39mload(name\u001b[38;5;241m=\u001b[39mmodule_name, verbose\u001b[38;5;241m=\u001b[39mverbose_build, sources\u001b[38;5;241m=\u001b[39msources, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_kwargs)\n",
      "File \u001b[0;32m/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/torch/utils/cpp_extension.py:993\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, keep_intermediates)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m    913\u001b[0m          sources: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    914\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m          is_python_module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    922\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    Loads a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m                verbose=True)\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1200\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, keep_intermediates)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m IS_HIP_EXTENSION \u001b[38;5;129;01mand\u001b[39;00m (with_cuda \u001b[38;5;129;01mor\u001b[39;00m with_cudnn):\n\u001b[1;32m   1191\u001b[0m             hipify_python\u001b[38;5;241m.\u001b[39mhipify(\n\u001b[1;32m   1192\u001b[0m                 project_directory\u001b[38;5;241m=\u001b[39mbuild_directory,\n\u001b[1;32m   1193\u001b[0m                 output_directory\u001b[38;5;241m=\u001b[39mbuild_directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 clean_ctx\u001b[38;5;241m=\u001b[39mclean_ctx\n\u001b[1;32m   1199\u001b[0m             )\n\u001b[0;32m-> 1200\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     baton\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1275\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_ninja_file_and_build_library\u001b[39m(\n\u001b[1;32m   1266\u001b[0m         name,\n\u001b[1;32m   1267\u001b[0m         sources: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         verbose: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   1274\u001b[0m         with_cuda: Optional[\u001b[38;5;28mbool\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1275\u001b[0m     \u001b[43mverify_ninja_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m IS_WINDOWS:\n\u001b[1;32m   1277\u001b[0m         compiler \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCXX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/work/emar349/shared/envs/torch-gpu-stylegan/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1330\u001b[0m, in \u001b[0;36mverify_ninja_availability\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;124;03mRaises ``RuntimeError`` if `ninja <https://ninja-build.org/>`_ build system is not\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03mavailable on the system, does nothing otherwise.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ninja_available():\n\u001b[0;32m-> 1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNinja is required to load C++ extensions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Ninja is required to load C++ extensions"
     ]
    }
   ],
   "source": [
    "#@markdown #**Model selection** 🎭\n",
    "\n",
    "Model = 'Imagenet' #@param [\"Imagenet\", \"Pokemon\", \"FFHQ\"]\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "network_url = {\n",
    "    \"Imagenet\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/imagenet512.pkl\",\n",
    "    \"Pokemon\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/pokemon256.pkl\",\n",
    "    \"FFHQ\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/ffhq256.pkl\"\n",
    "}\n",
    "\n",
    "model_path = \"/work/emar349/shared/stylegan-xl/\"\n",
    "network_name = network_url[Model].split(\"/\")[-1]\n",
    "fetch_model(network_url[Model])\n",
    "\n",
    "network_name = model_path+network_name\n",
    "\n",
    "with dnnlib.util.open_url(network_name) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
    "\n",
    "\n",
    "zs = torch.randn([10000, G.mapping.z_dim], device=device)\n",
    "cs = torch.zeros([10000, G.mapping.c_dim], device=device)\n",
    "for i in range(cs.shape[0]):\n",
    "  cs[i,i//10]=1\n",
    "w_stds = G.mapping(zs, cs)\n",
    "w_stds = w_stds.reshape(10, 1000, G.num_ws, -1)\n",
    "w_stds=w_stds.std(0).mean(0)[0]\n",
    "w_all_classes_avg = G.mapping.w_avg.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "01c3aba426af4c849b385a4bf4d56693",
      "f5ba1143090848fcb5ad05a20ff4d074",
      "177178145eca4a7ebb8cac7c45a020f1",
      "31a6dc3562cb4a0cb9253294332a5e33",
      "f6a4c7bda600401a90c0842a7fac57a3",
      "541931096c2b40898bebf2fe177d4af2",
      "dd38464dcc5f432ca53b6b369102fad1",
      "207c295555874917912f51ae91ff0ba1",
      "557fc74cde6c4ea5bf1c9fad8c43110c",
      "f9ab85c710694fbe8d14baabb30720a2",
      "2e5bba1db2b846ef8e46d4f3a1fc8306"
     ]
    },
    "id": "tAknegrdPM-d",
    "outputId": "9112a568-4168-488f-e9cf-1f5f8a119181"
   },
   "outputs": [],
   "source": [
    "#@markdown #**Run the model** 🚀\n",
    "#@markdown `texts`: Enter here a prompt to guide the image generation. You can enter more than one prompt separated with\n",
    "#@markdown `|`, which will cause the guidance to focus on the different prompts at the same time, allowing to mix and play\n",
    "#@markdown with the generation process.\n",
    "\n",
    "#@markdown `steps`: Number of optimization steps. The more steps, the longer it will try to generate an image relevant to the prompt.\n",
    "\n",
    "#@markdown `seed`: Determines the randomness seed. Using the same seed and prompt should give you similar results at every run.\n",
    "#@markdown Use `-1` for a random seed.\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "texts = \"a family of robotic seals\"#@param {type:\"string\"}\n",
    "steps = 501#@param {type:\"number\"}\n",
    "seed = 10 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "if seed == -1:\n",
    "    seed = np.random.randint(0,9e9)\n",
    "    print(f\"Your random seed is: {seed}\")\n",
    "\n",
    "texts = [frase.strip() for frase in texts.split(\"|\") if frase]\n",
    "\n",
    "targets = [clip_model.embed_text(text) for text in texts]\n",
    "\n",
    "\n",
    "'''\n",
    "zs = torch.randn([10000, G.mapping.z_dim], device=device)\n",
    "one_hot_class = torch.zeros(1000)\n",
    "initial_class = torch.randint(0,1000, (1,))[0]\n",
    "one_hot_class[initial_class]=1\n",
    "one_hot_class = one_hot_class.repeat((10000, 1))\n",
    "cs = one_hot_class.to(device)\n",
    "w_stds = G.mapping(zs, cs)\n",
    "w_stds=w_stds.std(0)[0]\n",
    "'''\n",
    "\n",
    "\n",
    "tf = Compose([\n",
    "  # Resize(224),\n",
    "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
    "])\n",
    "\n",
    "initial_batch=4 #actually that will be multiplied by initial_image_steps\n",
    "initial_image_steps=32\n",
    "'''\n",
    "c = torch.zeros((1000)) #just to pick a closer initial image\n",
    "c[initial_class]=1\n",
    "c = c.repeat(initial_batch, 1)\n",
    "c=c.to(device)\n",
    "'''\n",
    "def run(timestring):\n",
    "  torch.manual_seed(seed)\n",
    "  with torch.no_grad():\n",
    "    qs = []\n",
    "    losses = []\n",
    "    for _ in range(initial_image_steps):\n",
    "      a = torch.randn([initial_batch, 512], device=device)*0.4 + w_stds*0.4\n",
    "      q = ((a-w_all_classes_avg)/w_stds)\n",
    "      images = G.synthesis((q * w_stds + w_all_classes_avg).unsqueeze(1).repeat([1, G.num_ws, 1]))\n",
    "      embeds = embed_image(images.add(1).div(2))\n",
    "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
    "      i = torch.argmin(loss)\n",
    "      qs.append(q[i])\n",
    "      losses.append(loss[i])\n",
    "    qs = torch.stack(qs)\n",
    "    losses = torch.stack(losses)\n",
    "    # print(losses)\n",
    "    # print(losses.shape, qs.shape)\n",
    "    i = torch.argmin(losses)\n",
    "    q = qs[i].unsqueeze(0).repeat([G.num_ws, 1]).requires_grad_()\n",
    "\n",
    "\n",
    "  # Sampling loop\n",
    "  q_ema = q\n",
    "  print(q.shape)\n",
    "  opt = torch.optim.AdamW([q], lr=0.05, betas=(0., 0.999), weight_decay=0.025)\n",
    "  loop = tqdm(range(steps))\n",
    "  for i in loop:\n",
    "    opt.zero_grad()\n",
    "    w = q * w_stds\n",
    "    image = G.synthesis((q * w_stds + w_all_classes_avg)[None], noise_mode='const')\n",
    "    embed = embed_image(image.add(1).div(2))\n",
    "    loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
    "\n",
    "    q_ema = q_ema * 0.98 + q * 0.02\n",
    "    image = G.synthesis((q_ema * w_stds + w_all_classes_avg)[None], noise_mode='const')\n",
    "\n",
    "    if i % 50 == 0:\n",
    "      display(TF.to_pil_image(tf(image)[0]))\n",
    "      print(f\"Image {i}/{steps} | Current loss: {loss}\")\n",
    "    pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1))\n",
    "    os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
    "    pil_image.save(f'samples/{timestring}/{i:04}.jpg')\n",
    "\n",
    "try:\n",
    "  timestring = time.strftime('%Y%m%d%H%M%S')\n",
    "  run(timestring)\n",
    "except KeyboardInterrupt:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zi-j_mqCBP1r",
    "outputId": "c2785976-c4ee-4d44-9f40-f1f300194ce2"
   },
   "outputs": [],
   "source": [
    "!ls samples/*/0500.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "pOudXXDMBYde",
    "outputId": "776379a8-09b4-4107-a43c-11c2d598740e"
   },
   "outputs": [],
   "source": [
    "display(Image.open('samples/20220421001514/0500.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3T08C5FBsRN",
    "outputId": "d5f8f19b-c0f2-4824-d239-750b217fcf34"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -r 60 -i 'samples/20220421001514/%04d.jpg' -vcodec libx264 -crf 18 -pix_fmt yuv420p loom_of_the_gods.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmpNBbPeB61c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StyleganXL+CLIP (Modified)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (torch-gpu-stylegan)",
   "language": "python",
   "name": "torch-gpu-stylegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01c3aba426af4c849b385a4bf4d56693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5ba1143090848fcb5ad05a20ff4d074",
       "IPY_MODEL_177178145eca4a7ebb8cac7c45a020f1",
       "IPY_MODEL_31a6dc3562cb4a0cb9253294332a5e33"
      ],
      "layout": "IPY_MODEL_f6a4c7bda600401a90c0842a7fac57a3"
     }
    },
    "177178145eca4a7ebb8cac7c45a020f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_207c295555874917912f51ae91ff0ba1",
      "max": 501,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_557fc74cde6c4ea5bf1c9fad8c43110c",
      "value": 155
     }
    },
    "207c295555874917912f51ae91ff0ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e5bba1db2b846ef8e46d4f3a1fc8306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31a6dc3562cb4a0cb9253294332a5e33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9ab85c710694fbe8d14baabb30720a2",
      "placeholder": "​",
      "style": "IPY_MODEL_2e5bba1db2b846ef8e46d4f3a1fc8306",
      "value": " 155/501 [01:29&lt;03:21,  1.72it/s, loss=0.667, q_magnitude=0.788]"
     }
    },
    "541931096c2b40898bebf2fe177d4af2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "557fc74cde6c4ea5bf1c9fad8c43110c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd38464dcc5f432ca53b6b369102fad1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5ba1143090848fcb5ad05a20ff4d074": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_541931096c2b40898bebf2fe177d4af2",
      "placeholder": "​",
      "style": "IPY_MODEL_dd38464dcc5f432ca53b6b369102fad1",
      "value": " 31%"
     }
    },
    "f6a4c7bda600401a90c0842a7fac57a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9ab85c710694fbe8d14baabb30720a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
